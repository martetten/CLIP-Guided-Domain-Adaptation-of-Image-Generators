# CLIP-Guided Domain Adaptation of Image Generators
Адаптация домена генератора изображений с использованием сигналов модели CLIP

Проект реализует метод адаптации предобученного генератора изображений лиц (архитектура StyleGAN2) к генерации изображений в целевых художественных стилях без использования парных данных и без полного переобучения модели. Адаптация выполняется путём дообучения части слоёв генератора с использованием семантических признаков из пространства модели CLIP в качестве направляющего сигнала.

## Структура проекта

research.ipynb - ноутбук с исследованием архитектуры генератора, экспериментальным определением важности слоёв и обучением моделей для трёх целевых доменов (аниме, эскиз, акварель)

inference.ipynb - ноутбук для демонстрации результатов: генерация изображений в адаптированных стилях и редактирование реальных фотографий через инверсию в латентное пространство

models/ - папка с сохранёнными весами обученных моделей (файлы с расширением .pt, не загружалась ввиду объема)

pictures/ - папка с результатами визуализации: графики потерь, сравнительные изображения до и после адаптации, результаты редактирования реальных фотографий

stylegan2-ada-pytorch/ - официальная реализация генератора StyleGAN2 от NVlabs

## Установка и запуск

1. Установите зависимости:
   pip install -r requirements.txt

2. Запустите ноутбук research.ipynb для воспроизведения исследования и обучения моделей (требуется GPU с минимум 6 ГБ памяти, время выполнения ~75 минут)

3. Запустите ноутбук inference.ipynb для демонстрации результатов (время выполнения ~7 минут на GPU)

Примечание: веса предобученного генератора FFHQ и модели CLIP загружаются автоматически при первом запуске. Для редактирования реальных изображений поместите файлы с реальными изображениями в папку pictures/ (код ноутбука потребует изменений), либо используйте добавленные мной: hepburn.png, junger.png, steel.png, lynch.png.

## Краткая аннотация и выводы

Проект демонстрирует эффективность использования семантических признаков модели CLIP для адаптации домена генератора изображений. Экспериментальное исследование структуры генератора StyleGAN2 подтвердило гипотезу о том, что средние слои синтеза (соответствующие разрешениям 64–256 пикселей) лучше всего кодируют стилевые характеристики изображения. Обучение только средних слоёв позволило достичь значимого изменения стиля (аниме, скетч, акварель) при сохранении идентичности генерируемых лиц и отсутствии ярко выраженных артефактов.

Метод показал значимые результаты при генерации новых изображений в целевых доменах: косинусное сходство с текстовым промптом увеличилось на 0.08–0.11 по сравнению с исходным генератором, а визуальная оценка подтвердила успешный перенос стилевых характеристик. Однако при применении к реальным фотографиям через инверсию в латентное пространство возникли систематические артефакты. Эти ограничения объясняются фундаментальным несоответствием распределений: адаптация обучалась исключительно на сэмплах из распределения генератора, тогда как инвертированные коды реальных фотографий часто лежат за его пределами.

Полученные результаты подтверждают применимость метода для генерации изображений в новых доменах с минимальными вычислительными затратами, но указывают на необходимость дополнительных компонентов для качественного редактирования произвольных изображений: предобученного энкодера для точной инверсии и модуля выравнивания лиц для нормализации входных данных
